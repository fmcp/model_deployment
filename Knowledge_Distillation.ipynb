{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ow23zCFEH4v"
      },
      "source": [
        "# Ejemplo de Knowledge Distillation\n",
        "---\n",
        "\n",
        "En este ejemplo vamos a ver como entrenar un modelo pequeño (número reducido capas y pesos) que replique el comportamiento de un modelo más grande que tiene un mayor accuracy pero con un tiempo de inferencia y uso de recursos mayor. Para ello, vamos a seguir un esquema teacher-student. De esta forma, esta técnica proporciona dos beneficios potenciales:\n",
        "\n",
        "\n",
        "1.   Reducimos el tamaño del modelo por lo que ocupa menos en memoria y se ejecuta más rápido.\n",
        "2.   Un modelo de tamaño de reducido con el rendimiento de uno mucho más complejo.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Instalar e importar las librerías necesarias\n",
        "\n",
        "En este ejemplo vamos a trabajar con Pytorch y los modelos de torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnsq0y32D6KW",
        "outputId": "617f16fe-e881-43a1-a439-cacb2e35ed2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QcTQd3QwEM5j"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights, resnet50, ResNet50_Weights\n",
        "from torchinfo import summary\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk6e0K0QGkOa"
      },
      "source": [
        "## 2. Definir los modelos\n",
        "\n",
        "Definimos el modelo teacher y el modelo student con una serie de capas básicas para obtener un rendimiento aceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HFcF5CW9DU5",
        "outputId": "51755d79-9513-4df6-ab8b-52d1d43c1b34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
              "============================================================================================================================================\n",
              "Teacher                                  [1, 3, 32, 32]            [1, 10]                   --                        --\n",
              "├─Conv2d: 1-1                            [1, 3, 32, 32]            [1, 32, 32, 32]           896                       917,504\n",
              "├─MaxPool2d: 1-2                         [1, 32, 32, 32]           [1, 32, 16, 16]           --                        --\n",
              "├─Conv2d: 1-3                            [1, 32, 16, 16]           [1, 64, 16, 16]           18,496                    4,734,976\n",
              "├─MaxPool2d: 1-4                         [1, 64, 16, 16]           [1, 64, 8, 8]             --                        --\n",
              "├─Conv2d: 1-5                            [1, 64, 8, 8]             [1, 128, 8, 8]            73,856                    4,726,784\n",
              "├─MaxPool2d: 1-6                         [1, 128, 8, 8]            [1, 128, 4, 4]            --                        --\n",
              "├─Conv2d: 1-7                            [1, 128, 4, 4]            [1, 256, 4, 4]            295,168                   4,722,688\n",
              "├─MaxPool2d: 1-8                         [1, 256, 4, 4]            [1, 256, 2, 2]            --                        --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [1, 256, 2, 2]            [1, 256, 1, 1]            --                        --\n",
              "├─Linear: 1-10                           [1, 256]                  [1, 128]                  32,896                    32,896\n",
              "├─Linear: 1-11                           [1, 128]                  [1, 64]                   8,256                     8,256\n",
              "├─Linear: 1-12                           [1, 64]                   [1, 10]                   650                       650\n",
              "============================================================================================================================================\n",
              "Total params: 430,218\n",
              "Trainable params: 430,218\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 15.14\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.49\n",
              "Params size (MB): 1.72\n",
              "Estimated Total Size (MB): 2.23\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "teacher = Teacher()\n",
        "summary(teacher, input_size=(1, 3, 32, 32), col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABcZWwg4Jece",
        "outputId": "0f4c73d1-3464-4285-95c4-48877bf43023"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Student                                  [1, 10]                   --\n",
              "├─Conv2d: 1-1                            [1, 16, 32, 32]           448\n",
              "├─MaxPool2d: 1-2                         [1, 16, 16, 16]           --\n",
              "├─Conv2d: 1-3                            [1, 32, 16, 16]           4,640\n",
              "├─MaxPool2d: 1-4                         [1, 32, 8, 8]             --\n",
              "├─Conv2d: 1-5                            [1, 64, 8, 8]             18,496\n",
              "├─MaxPool2d: 1-6                         [1, 64, 4, 4]             --\n",
              "├─Conv2d: 1-7                            [1, 128, 4, 4]            73,856\n",
              "├─MaxPool2d: 1-8                         [1, 128, 2, 2]            --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [1, 128, 1, 1]            --\n",
              "├─Linear: 1-10                           [1, 10]                   1,290\n",
              "==========================================================================================\n",
              "Total params: 98,730\n",
              "Trainable params: 98,730\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 4.01\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.25\n",
              "Params size (MB): 0.39\n",
              "Estimated Total Size (MB): 0.65\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "class Student(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "student = Student()\n",
        "summary(student, input_size=(1, 3, 32, 32), col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEdYSwpwM2gn"
      },
      "source": [
        "## 3. Definir un data loader\n",
        "\n",
        "Por limitaciones de tiempo de cómputo, vamos a trabajar con CIFAR-10 pero cualquier dataset es válido. Primero, tenemos que crear un DataLoader de Pytorch para poder usar los datos con nuestro modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN8vwaeNb6tU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e10be36-7edc-42b1-ecb2-efeae7606cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_data_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_data_loader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt_pFyGCMVnd"
      },
      "source": [
        "##4. Entrenar modelos base\n",
        "Una vez cargados los datos, realizamos un entrenamiento inicial de los modelos teacher y student y medimos su accuracy inicial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt3ee3Y9MZQY",
        "outputId": "dca38280-4910-47b3-de14-513ee46d168b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Training Teacher **\n",
            "** Summary for epoch 0: loss: 1.58, acc: 41.1]  time: 18.246s **\n",
            "** Summary for epoch 1: loss: 1.15, acc: 58.4]  time: 15.279s **\n",
            "** Summary for epoch 2: loss: 0.929, acc: 66.9]  time: 13.973s **\n",
            "** Summary for epoch 3: loss: 0.786, acc: 72.0]  time: 14.027s **\n",
            "** Summary for epoch 4: loss: 0.687, acc: 76.0]  time: 14.495s **\n",
            "** Summary for epoch 5: loss: 0.595, acc: 79.0]  time: 14.184s **\n",
            "** Summary for epoch 6: loss: 0.518, acc: 81.9]  time: 14.071s **\n",
            "** Summary for epoch 7: loss: 0.453, acc: 84.0]  time: 14.147s **\n",
            "** Summary for epoch 8: loss: 0.387, acc: 86.2]  time: 15.525s **\n",
            "** Summary for epoch 9: loss: 0.326, acc: 88.5]  time: 13.958s **\n",
            "** Summary for teacher: acc: 76.8]  time: 2.653s **\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "print(f'** Training Teacher **')\n",
        "opt = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "teacher.train().to('cuda')\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        opt.zero_grad()\n",
        "        outs_teacher = teacher(inputs)\n",
        "        loss = loss_fn(outs_teacher, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(outs_teacher.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        counter = counter + 1\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss: {epoch_loss:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')\n",
        "\n",
        "# Test\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in test_data_loader: # Obtenemos todos los batch de test y los usamos para test\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outs_teacher = teacher(inputs)\n",
        "        _, preds = torch.max(outs_teacher.data, 1)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = 100. * (test_correct / len(test_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for teacher: '\n",
        "\t\tf'acc: {acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOdAvKSuG-Uu",
        "outputId": "c519eb88-c67f-4a76-e5ad-0815e2b72e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Training Student **\n",
            "** Summary for epoch 0: loss: 1.72, acc: 36.5]  time: 14.386s **\n",
            "** Summary for epoch 1: loss: 1.41, acc: 48.6]  time: 13.588s **\n",
            "** Summary for epoch 2: loss: 1.27, acc: 54.4]  time: 13.798s **\n",
            "** Summary for epoch 3: loss: 1.17, acc: 58.6]  time: 13.849s **\n",
            "** Summary for epoch 4: loss: 1.06, acc: 62.3]  time: 13.761s **\n",
            "** Summary for epoch 5: loss: 0.992, acc: 64.8]  time: 13.835s **\n",
            "** Summary for epoch 6: loss: 0.929, acc: 67.2]  time: 13.658s **\n",
            "** Summary for epoch 7: loss: 0.886, acc: 68.7]  time: 13.782s **\n",
            "** Summary for epoch 8: loss: 0.830, acc: 70.8]  time: 13.536s **\n",
            "** Summary for epoch 9: loss: 0.790, acc: 72.4]  time: 13.578s **\n",
            "** Summary for student: acc: 69.4]  time: 3.645s **\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "print(f'** Training Student **')\n",
        "opt = torch.optim.Adam(student.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "student.train().to('cuda')\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        opt.zero_grad()\n",
        "        outs_student = student(inputs)\n",
        "        loss = loss_fn(outs_student, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(outs_student.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        counter = counter + 1\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss: {epoch_loss:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')\n",
        "\n",
        "# Test\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in test_data_loader: # Obtenemos todos los batch de test y los usamos para test\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outs_student = student(inputs)\n",
        "        _, preds = torch.max(outs_student.data, 1)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = 100. * (test_correct / len(test_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for student: '\n",
        "\t\tf'acc: {acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **') #70.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPFQTzjQQo7Q"
      },
      "source": [
        "## 5. Knowledge Distillation del modelo student\n",
        "\n",
        "Realizamos unas épocas para hacer que los pesos del modelo student repliquen el comportamiento del modelo teacher. Para ello, para cada batch, hacemos una inferencia del modelo teacher para obtener su comportamiento y luiego intentamos replicar la salida en el modelo student. Para ello, usamos la base de datos que hemos descargado en el punto 3. Además, como función de loss usamos la Hinton Loss cuya ecuación es la siguiente:\n",
        "\n",
        "Loss = $-\\sum_{c=1}^My_{o,c}\\log(\\frac{p_{o,c}}{T})$\n",
        "\n",
        "Básicamente, es una Crossentropy loss con los logits divididos por la T (temperatura) cuyo valor normalmente es 2.0. Si usamos T=1.0, estaríamos usando una Crossentropy loss normal y corriente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVUI780Mx8s",
        "outputId": "b668d741-4a2b-4de0-baa1-d92a74772a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Summary for epoch 0: loss_dist: 1.10, acc: 73.1]  time: 13.981s **\n",
            "** Summary for epoch 1: loss_dist: 1.08, acc: 74.0]  time: 14.169s **\n",
            "** Summary for epoch 2: loss_dist: 1.06, acc: 74.7]  time: 13.894s **\n",
            "** Summary for epoch 3: loss_dist: 1.05, acc: 75.2]  time: 13.925s **\n",
            "** Summary for epoch 4: loss_dist: 1.04, acc: 75.8]  time: 15.415s **\n",
            "** Summary for epoch 5: loss_dist: 1.03, acc: 76.3]  time: 13.846s **\n",
            "** Summary for epoch 6: loss_dist: 1.02, acc: 76.7]  time: 14.150s **\n",
            "** Summary for epoch 7: loss_dist: 1.02, acc: 77.2]  time: 13.639s **\n",
            "** Summary for epoch 8: loss_dist: 1.01, acc: 77.5]  time: 14.031s **\n",
            "** Summary for epoch 9: loss_dist: 1.00, acc: 77.9]  time: 13.656s **\n",
            "** Summary for final model: acc: 73.2]  time: 2.527s **\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "opt = torch.optim.Adam(student.parameters(), lr=0.0005)\n",
        "dist_loss_fn = torch.nn.CrossEntropyLoss()\n",
        "teacher.eval()\n",
        "student.train().to('cuda')\n",
        "T = 2.0\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    train_running_loss_dist = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        opt.zero_grad()\n",
        "        with torch.no_grad():\n",
        "          outs_teacher = teacher(inputs) / T\n",
        "          outs_teacher = torch.nn.functional.softmax(outs_teacher, dim=1)\n",
        "\n",
        "        outs_student = student(inputs)\n",
        "        loss_dist = dist_loss_fn(outs_student / T, outs_teacher)\n",
        "        train_running_loss_dist += loss_dist.item()\n",
        "        _, preds = torch.max(outs_student.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        counter = counter + 1\n",
        "        loss_dist.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss_dist = train_running_loss_dist / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss_dist: {epoch_loss_dist:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')\n",
        "\n",
        "# Test\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in test_data_loader: # Obtenemos todos los batch de test y los usamos para test\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outs_student = student(inputs)\n",
        "        _, preds = torch.max(outs_student.data, 1)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = 100. * (test_correct / len(test_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for final model: '\n",
        "\t\tf'acc: {acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxGT16QHQ6a0"
      },
      "source": [
        "## 6. Exportar el modelo\n",
        "\n",
        "Una vez que hemos realizado el entrenamiento modelo student, exportamos el modelo a un fichero para poder usarlo en nuestra aplicación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTIDTKCLidSO"
      },
      "outputs": [],
      "source": [
        "student.eval()\n",
        "torch.save(student.state_dict(), '.student.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcIiFXF7ROfO"
      },
      "source": [
        "Además, vamos a realizar una  inferencia de prueba para analizar el rendimiento del modelo teacher y del student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNE3EyU6JUx4",
        "outputId": "bfb3cdd2-5ac9-4c6c-8fee-39dea7315791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of the teacher model: 0.006s\n",
            "Execution time of the student model: 0.005s\n"
          ]
        }
      ],
      "source": [
        "image = torch.Tensor(np.random.rand(1,3,224,244)).float().cuda()\n",
        "\n",
        "# Teacher model\n",
        "times = []\n",
        "for i in range(50):\n",
        "    torch.cuda.synchronize()  # Sincroniza antes de empezar a medir\n",
        "    time_start = time.time()\n",
        "    teacher(image)\n",
        "    torch.cuda.synchronize()  # Espera a que la ejecución en la GPU termine\n",
        "    time_end = time.time() - time_start\n",
        "    times.append(time_end)\n",
        "\n",
        "time_end = np.mean(times)\n",
        "print(f'Execution time of the teacher model: {time_end:.3f}s')\n",
        "\n",
        "# Student model\n",
        "times = []\n",
        "for i in range(50):\n",
        "    torch.cuda.synchronize()  # Sincroniza antes de empezar a medir\n",
        "    time_start = time.time()\n",
        "    student(image)\n",
        "    torch.cuda.synchronize()  # Espera a que la ejecución en la GPU termine\n",
        "    time_end = time.time() - time_start\n",
        "    times.append(time_end)\n",
        "\n",
        "time_end = np.mean(times)\n",
        "print(f'Execution time of the student model: {time_end:.3f}s')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}