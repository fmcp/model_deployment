{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ow23zCFEH4v"
      },
      "source": [
        "# Ejemplo de Pruning\n",
        "---\n",
        "\n",
        "En este ejemplo vamos a ver como eliminar filtros completos de un modelo para ahorrar cómputo y memoria. Para ello, vamos a aplicar pruning estructurado para eliminar un porcentaje de filtros de cada capa. Para ello, vamos a seguir los siguientes pasos:\n",
        "\n",
        "1.   Partimos de un modelo preentrenado.\n",
        "2.   Aplicamos el pruning y eliminamos aquellos filtros menos importantes en función de un criterio predefinido (norma L2 en nuestro caso).\n",
        "3.   Aplicamos un fine tuning para ajustar los pesos frente a los nuevos cambios\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Instalar e importar las librerías necesarias\n",
        "\n",
        "En este ejemplo vamos a trabajar con Pytorch y los modelos de torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnsq0y32D6KW",
        "outputId": "a1169013-e531-4db0-c6f3-e6ea9569cea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcTQd3QwEM5j"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "from torchinfo import summary\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk6e0K0QGkOa"
      },
      "source": [
        "## 2. Definir los modelos\n",
        "\n",
        "Por simplicidad, vamos a trabajar con Alexnet que es un modelo lineal sin conexiones residuales. Esto no es por requirimientos del pruning, es por facilidad de programar la eliminación de filtros. A cualquier modelo se le puede aplicar pruning, simplemente hay que tener en cuenta dependencias de las conexiones residuales para eliminar los filtros a 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HFcF5CW9DU5",
        "outputId": "6e9df11f-485b-4619-a8dc-5dbaaf289ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "AlexNet                                  [1, 1000]                 --\n",
              "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n",
              "│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n",
              "│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n",
              "│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n",
              "│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n",
              "│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n",
              "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n",
              "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
              "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n",
              "│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n",
              "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
              "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n",
              "├─Sequential: 1-3                        [1, 1000]                 --\n",
              "│    └─Dropout: 2-14                     [1, 9216]                 --\n",
              "│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n",
              "│    └─ReLU: 2-16                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-17                     [1, 4096]                 --\n",
              "│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-19                        [1, 4096]                 --\n",
              "│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 61,100,840\n",
              "Trainable params: 61,100,840\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 714.68\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 3.95\n",
              "Params size (MB): 244.40\n",
              "Estimated Total Size (MB): 248.96\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model = torchvision.models.alexnet(weights=AlexNet_Weights)\n",
        "preprocessing = AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEdYSwpwM2gn"
      },
      "source": [
        "## 3. Definir un data loader\n",
        "\n",
        "Por limitaciones de tiempo de cómputo, vamos a trabajar con CIFAR-10 pero cualquier dataset es válido. Primero, tenemos que crear un DataLoader de Pytorch para poder usar los datos con nuestro modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN8vwaeNb6tU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81408a8d-0d61-441b-e6f9-86cafa8db105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=preprocessing)\n",
        "train_data_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=preprocessing)\n",
        "test_data_loader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fine tuning a CIFAR-10\n",
        "Como torchvision solo proporciona los pesos para ImageNet, tenemos que hacer un fine tuning inicial a CIFAR-10 para ajustar el modelo al nuevo dataset. Usar ImageNet en este ejemplo no es posible porque ocupa varios cientos de GB!"
      ],
      "metadata": {
        "id": "cMvcr1Z7KmZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1\n",
        "print(f'** FT a CIFAR-10 **')\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model.train().to('cuda')\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        opt.zero_grad()\n",
        "        outs_model = model(inputs)\n",
        "        loss = loss_fn(outs_model, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(outs_model.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        counter = counter + 1\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss: {epoch_loss:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')\n",
        "\n",
        "# Test\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in test_data_loader: # Obtenemos todos los batch de test y los usamos para test\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outs_model = model(inputs)\n",
        "        _, preds = torch.max(outs_model.data, 1)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = 100. * (test_correct / len(test_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for model: '\n",
        "\t\tf'acc: {acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "yj8YtVIDKoQ_",
        "outputId": "de9e90d0-d252-4882-ca3f-0988665bdc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** FT a CIFAR-10 **\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-218215065.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_running_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt_pFyGCMVnd"
      },
      "source": [
        "## 5. Aplicar el pruning\n",
        "En este proceso vamos a aplicar el pruning, es decir, primero vamos a seleccionar los filtros a eliminar y luego, usando las funciones auxiliares que hemos creado, vamos a generar una nueva red eliminando esos filtros."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_network_structured(model_to_prune, layers_to_prune_config):\n",
        "    \"\"\"\n",
        "    Fase 1: Aplica poda estructurada para poner pesos a cero en las capas especificadas.\n",
        "    Modifica el modelo in-situ.\n",
        "\n",
        "    Args:\n",
        "        model_to_prune (nn.Module): El modelo a podar.\n",
        "        layers_to_prune_config (dict): Un diccionario que mapea el módulo a podar\n",
        "                                        a la fracción de poda.\n",
        "                                        Ej: {model.features[0]: 0.25}\n",
        "    \"\"\"\n",
        "    print(\"--- FASE 1: Generando ceros con poda estructurada ---\")\n",
        "    for layer, amount in layers_to_prune_config.items():\n",
        "        if amount > 0 and isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "            print(f\"Podando el {amount*100:.0f}% de {layer.__class__.__name__} (capa {list(layers_to_prune_config.keys()).index(layer)})\")\n",
        "            prune.ln_structured(layer, name=\"weight\", amount=amount, n=1, dim=0)\n",
        "            # Hacemos la poda permanente en el tensor de pesos\n",
        "            prune.remove(layer, \"weight\")\n",
        "    print(\"Ceros generados.\\n\")\n",
        "    return model_to_prune\n",
        "\n",
        "\n",
        "def _prune_sequential_module(sequential_module, last_conv_output_channels=None):\n",
        "    \"\"\"\n",
        "    Helper para la Fase 2: Reconstruye un módulo nn.Sequential eliminando\n",
        "    físicamente las capas con pesos a cero.\n",
        "    \"\"\"\n",
        "    new_layers = []\n",
        "    # Índices de los canales/neuronas eliminados en la capa ANTERIOR\n",
        "    last_layer_pruned_indices = None\n",
        "\n",
        "    # Si es el clasificador, la primera capa lineal necesita un trato especial\n",
        "    is_classifier = any(isinstance(m, nn.Linear) for m in sequential_module)\n",
        "    first_linear_handled = not is_classifier\n",
        "\n",
        "    for layer in sequential_module.children():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # 1. Ajustar canales de entrada si la capa anterior fue podada\n",
        "            if last_layer_pruned_indices is not None:\n",
        "                keep_indices = [i for i in range(layer.in_channels) if i not in last_layer_pruned_indices]\n",
        "                layer.in_channels = len(keep_indices)\n",
        "                # La poda de grupos requiere una lógica más compleja, asumimos groups=1 o poda simétrica\n",
        "                if layer.groups > 1 and len(keep_indices) % layer.groups != 0:\n",
        "                     print(f\"Warning: Group convolution might be inconsistent after pruning. In channels: {len(keep_indices)}, Groups: {layer.groups}\")\n",
        "                layer.weight = nn.Parameter(layer.weight.data.clone()[:, keep_indices, :, :])\n",
        "\n",
        "            # 2. Identificar y podar filtros de salida nulos\n",
        "            sum_of_weights = torch.sum(torch.abs(layer.weight.data), dim=(1, 2, 3))\n",
        "            non_zero_indices = torch.where(sum_of_weights != 0)[0]\n",
        "\n",
        "            # Crear y añadir la nueva capa\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=layer.in_channels,\n",
        "                out_channels=len(non_zero_indices),\n",
        "                kernel_size=layer.kernel_size, stride=layer.stride,\n",
        "                padding=layer.padding, bias=(layer.bias is not None),\n",
        "                groups=layer.groups\n",
        "            )\n",
        "            new_conv.weight.data = layer.weight.data[non_zero_indices].clone()\n",
        "            if layer.bias is not None:\n",
        "                new_conv.bias.data = layer.bias.data[non_zero_indices].clone()\n",
        "            new_layers.append(new_conv)\n",
        "\n",
        "            # 3. Guardar índices podados para la siguiente capa\n",
        "            all_indices = set(range(layer.out_channels))\n",
        "            kept_indices = set(non_zero_indices.tolist())\n",
        "            last_layer_pruned_indices = list(all_indices - kept_indices)\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # 1. Ajustar neuronas de entrada\n",
        "            # Caso especial: primera capa del clasificador de AlexNet\n",
        "            if not first_linear_handled and last_conv_output_channels is not None:\n",
        "                # El in_features de AlexNet es out_channels * 6 * 6\n",
        "                new_in_features = last_conv_output_channels * 6 * 6\n",
        "                layer.in_features = new_in_features\n",
        "                original_weights = layer.weight.data.clone()\n",
        "                # Ajustamos la matriz de pesos para que coincida con la nueva entrada\n",
        "                # Esto es una simplificación, puede que no sea óptimo para todas las arquitecturas\n",
        "                layer.weight = nn.Parameter(original_weights[:, :new_in_features])\n",
        "                first_linear_handled = True\n",
        "            # Caso general: una capa lineal sigue a otra lineal que fue podada\n",
        "            elif last_layer_pruned_indices is not None:\n",
        "                keep_indices = [i for i in range(layer.in_features) if i not in last_layer_pruned_indices]\n",
        "                layer.in_features = len(keep_indices)\n",
        "                layer.weight = nn.Parameter(layer.weight.data.clone()[:, keep_indices])\n",
        "\n",
        "            # 2. Identificar y podar neuronas de salida nulas\n",
        "            sum_of_weights = torch.sum(torch.abs(layer.weight.data), dim=1)\n",
        "            non_zero_indices = torch.where(sum_of_weights != 0)[0]\n",
        "\n",
        "            # Evitar crear una capa final con cero neuronas si es la capa de salida\n",
        "            if len(non_zero_indices) == 0 and len(new_layers) > 0 and isinstance(sequential_module[-1], nn.Linear):\n",
        "                print(\"Warning: La capa de salida ha sido completamente podada. Se mantendrá 1 neurona para evitar errores.\")\n",
        "                non_zero_indices = torch.tensor([0]) # Mantener al menos una neurona\n",
        "\n",
        "            new_linear = nn.Linear(\n",
        "                in_features=layer.in_features,\n",
        "                out_features=len(non_zero_indices),\n",
        "                bias=(layer.bias is not None)\n",
        "            )\n",
        "            new_linear.weight.data = layer.weight.data[non_zero_indices].clone()\n",
        "            if layer.bias is not None:\n",
        "                new_linear.bias.data = layer.bias.data[non_zero_indices].clone()\n",
        "            new_layers.append(new_linear)\n",
        "\n",
        "            # 3. Guardar índices podados\n",
        "            all_indices = set(range(layer.out_features))\n",
        "            kept_indices = set(non_zero_indices.tolist())\n",
        "            last_layer_pruned_indices = list(all_indices - kept_indices)\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            if last_layer_pruned_indices:\n",
        "                keep_indices = [i for i in range(layer.num_features) if i not in last_layer_pruned_indices]\n",
        "                new_bn = nn.BatchNorm2d(len(keep_indices))\n",
        "                new_bn.weight.data = layer.weight.data[keep_indices].clone()\n",
        "                new_bn.bias.data = layer.bias.data[keep_indices].clone()\n",
        "                new_bn.running_mean = layer.running_mean[keep_indices].clone()\n",
        "                new_bn.running_var = layer.running_var[keep_indices].clone()\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(layer)\n",
        "\n",
        "        else: # ReLU, MaxPool2d, Dropout, etc.\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers)"
      ],
      "metadata": {
        "id": "ruv2AWYaFu81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_compact_model(model_with_zeros):\n",
        "    \"\"\"\n",
        "    Fase 2: Reconstruye un modelo AlexNet para eliminar físicamente las capas con ceros.\n",
        "\n",
        "    Args:\n",
        "        model_with_zeros (nn.Module): El modelo AlexNet que ya tiene filtros/neuronas a cero.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: Un nuevo modelo compacto y coherente.\n",
        "    \"\"\"\n",
        "    print(\"--- FASE 2: Creando modelo compacto (eliminación física) ---\")\n",
        "    compact_model = copy.deepcopy(model_with_zeros)\n",
        "\n",
        "    # 1. Podar el módulo 'features'\n",
        "    compact_model.features = _prune_sequential_module(compact_model.features)\n",
        "    print(\"Módulo 'features' reconstruido.\")\n",
        "\n",
        "    # 2. Calcular el nuevo tamaño de entrada para el clasificador\n",
        "    last_conv = next(m for m in reversed(compact_model.features) if isinstance(m, nn.Conv2d))\n",
        "    last_conv_output_channels = last_conv.out_channels\n",
        "    print(f\"Nuevos canales de salida de 'features': {last_conv_output_channels}\")\n",
        "\n",
        "    # 3. Podar el módulo 'classifier'\n",
        "    compact_model.classifier = _prune_sequential_module(\n",
        "        compact_model.classifier,\n",
        "        last_conv_output_channels=last_conv_output_channels\n",
        "    )\n",
        "    print(\"Módulo 'classifier' reconstruido y ajustado.\")\n",
        "    print(\"Modelo compacto creado.\\n\")\n",
        "    return compact_model"
      ],
      "metadata": {
        "id": "G94zda7GJOkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# FASE 1: Aplicar poda para generar ceros\n",
        "# --------------------------------------------------------------------------\n",
        "model_to_prune = copy.deepcopy(model)\n",
        "\n",
        "# Tasa de poda uniforme para todas las capas. ¡Puedes cambiar este valor!\n",
        "PRUNING_RATE = 0.20 # 20%\n",
        "\n",
        "# --- Creación automática de la configuración de poda ---\n",
        "layers_to_prune_config = {}\n",
        "# Recorrer módulos 'features' y 'classifier' para encontrar capas podables\n",
        "for module in [model_to_prune.features, model_to_prune.classifier]:\n",
        "    for layer in module.children():\n",
        "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "            # No podar la última capa (salida de clasificación)\n",
        "            if layer == model_to_prune.classifier[-1]:\n",
        "                  layers_to_prune_config[layer] = 0.0\n",
        "            else:\n",
        "                  layers_to_prune_config[layer] = PRUNING_RATE\n",
        "\n",
        "print(f\"Configuración de poda creada para {len(layers_to_prune_config)} capas con una tasa del {PRUNING_RATE*100}%\\n\")\n",
        "\n",
        "# Ejecutar la poda para poner pesos a cero\n",
        "model_with_zeros = prune_network_structured(model_to_prune, layers_to_prune_config)\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# FASE 2: Reconstruir el modelo para eliminar los ceros físicamente\n",
        "# --------------------------------------------------------------------------\n",
        "compact_model = create_compact_model(model_with_zeros)\n",
        "\n",
        "print(\"--- Modelo Compacto Final ---\")\n",
        "print(compact_model)\n",
        "params_compact = sum(p.numel() for p in compact_model.parameters() if p.requires_grad)\n",
        "print(f\"Parámetros entrenables finales: {params_compact:,}\")\n",
        "params_original = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "reduction = 100 * (1 - params_compact / params_original)\n",
        "print(f\"Reducción total de parámetros: {reduction:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "ahGfEToCI4IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Fine tuning final\n",
        "Este paso es crítico para ajustar los pesos y mejorar el comportamiento del modelo ya que hemos eliminado un porcentaje de filtros que ahora no están y el rendimiento se va a ver resentido."
      ],
      "metadata": {
        "id": "xN0TitZYFvhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt3ee3Y9MZQY"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1\n",
        "print(f'** FT the pruned model **')\n",
        "opt = torch.optim.Adam(compact_model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "compact_model.train().to('cuda')\n",
        "for epoch in range(n_epochs): # Entrenamos n epocas\n",
        "    # Entrenamiento\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    train_counter = 0\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in train_data_loader: # Obtenemos todos los batch de entrenamiento y los usamos para entrenar\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = compact_model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        train_counter = train_counter + 1\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(train_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for epoch {epoch}: '\n",
        "\t\tf'loss: {epoch_loss:#.3g}, acc: {epoch_acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')\n",
        "\n",
        "# Test\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    time_start = time.time()\n",
        "    for inputs, labels in test_data_loader: # Obtenemos todos los batch de test y los usamos para test\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outs_compact_model = compact_model(inputs)\n",
        "        _, preds = torch.max(outs_compact_model.data, 1)\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = 100. * (test_correct / len(test_data_loader.dataset))\n",
        "    time_end = time.time() - time_start\n",
        "    print(f'** Summary for compact_model: '\n",
        "\t\tf'acc: {acc:#.3g}]  '\n",
        "\t\tf'time: {time_end:.3f}s **')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxGT16QHQ6a0"
      },
      "source": [
        "## 7. Exportar el modelo\n",
        "\n",
        "Una vez que hemos realizado el fine tuning del modelo compactado, exportamos el modelo a un fichero para poder usarlo en nuestra aplicación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTIDTKCLidSO"
      },
      "outputs": [],
      "source": [
        "compact_model.eval()\n",
        "torch.save(compact_model.state_dict(), '.compact_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcIiFXF7ROfO"
      },
      "source": [
        "Además, vamos a realizar una  inferencia de prueba para analizar el rendimiento del modelo original y del compactado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNE3EyU6JUx4"
      },
      "outputs": [],
      "source": [
        "image = torch.Tensor(np.random.rand(1,3,224,244)).float().cuda()\n",
        "model.eval().to('cuda')\n",
        "compact_model.eval().to('cuda')\n",
        "\n",
        "# Original model\n",
        "times = []\n",
        "for i in range(50):\n",
        "    torch.cuda.synchronize()  # Sincroniza antes de empezar a medir\n",
        "    time_start = time.time()\n",
        "    model(image)\n",
        "    torch.cuda.synchronize()  # Espera a que la ejecución en la GPU termine\n",
        "    time_end = time.time() - time_start\n",
        "    times.append(time_end)\n",
        "\n",
        "time_end = np.mean(times)\n",
        "print(f'Execution time of the original model: {time_end:.3f}s')\n",
        "\n",
        "# Pruned model\n",
        "times = []\n",
        "for i in range(50):\n",
        "    torch.cuda.synchronize()  # Sincroniza antes de empezar a medir\n",
        "    time_start = time.time()\n",
        "    compact_model(image)\n",
        "    torch.cuda.synchronize()  # Espera a que la ejecución en la GPU termine\n",
        "    time_end = time.time() - time_start\n",
        "    times.append(time_end)\n",
        "\n",
        "time_end = np.mean(times)\n",
        "print(f'Execution time of the pruned model: {time_end:.3f}s')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}